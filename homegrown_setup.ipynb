{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AbbhinavJayaraman/HCI-Grad-Course/blob/main/homegrown_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GbKnkZehINw"
   },
   "source": [
    "Since ChatGPT and existing LLMs are being annoying, we are just going to follow an existing setup that can be tweaked, making use of ollama since performance on one of our laptops running an modified Fedora Linux distrubtion was able tobe fast and responsive.\n",
    "\n",
    "Still need to figure out how to connect this with either the PRAAT scripts or myprosody:\n",
    "\n",
    "Links:\n",
    "Whisper + ollama + Bark framework: https://medium.com/@vndee.huynh/build-your-own-voice-assistant-and-run-it-locally-whisper-ollama-bark-c80e6f815cba\n",
    "\n",
    "PRAAT in python: https://github.com/YannickJadoul/Parselmouth\n",
    "myprosody: https://github.com/Shahabks/myprosody\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the following packages to install properly, you will need to make sure you on python version 3.12\n",
    "\n",
    "Install python version 3.12 (we used Homebrew), and then made a python venv with it (python3.12 -m venv sts), where sts is just a name of the venv.\n",
    "\n",
    "then you can activate the venv using source sts/bin/activate\n",
    "\n",
    "also make sure you have the portaudio library installed. For Mac, make use of the Homebrew package manager. \n",
    "\n",
    "For linux distrubitions, it's best to use the default package manager's version of portaudio, as well as the development headers (for us, that was portaudio-devel on Fedora Silverblue Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk\n",
    "# %pip install torch\n",
    "# %pip install numpy\n",
    "# %pip install transformers\n",
    "# %pip install openai-whisper\n",
    "# %pip install sounddevice\n",
    "# %pip install rich\n",
    "# %pip install langchain\n",
    "# %pip install langchain_community\n",
    "# %pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Save the STT file locally as generic name\n",
    "# process transcription\n",
    "# copy file to archive, or just return and do that after.\n",
    "\n",
    "# get the output, can just not print also\n",
    "\n",
    "# Function to delete a file\n",
    "def delete_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"File {file_path} deleted successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: {file_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while deleting file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def copy_file (dst: str, src: str, rm_src: bool=False) :\n",
    "    try:\n",
    "        shutil.copy(src, dst)  # Preserves metadata like timestamps\n",
    "        print(f\"File copied successfully from {src} to {dst}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    if rm_src :\n",
    "        delete_file(src)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myprosody as mysp\n",
    "import numpy as np\n",
    "\n",
    "import io\n",
    "import sys\n",
    "\n",
    "# Redirect the print output\n",
    "def detect_sr(src: str) -> int:\n",
    "    # Create a StringIO object to capture the output\n",
    "    p=src\n",
    "    c=r\"/var/home/jayabbhi/Documents/HCI_grad_project/myprosody/myprosody\"\n",
    "\n",
    "    captured_output = io.StringIO()\n",
    "    sys.stdout = captured_output  # Redirect sys.stdout to the StringIO object\n",
    "    try:\n",
    "        # Call the function whose output you want to capture\n",
    "        mysp.myspsr(p,c)\n",
    "    finally:\n",
    "        sys.stdout = sys.__stdout__  # Restore the original sys.stdout\n",
    "\n",
    "    # Get the captured output as a string\n",
    "    output = captured_output.getvalue()\n",
    "    captured_output.close()  # Close the StringIO object\n",
    "    \n",
    "    final_syl_sec = 8\n",
    "    try:\n",
    "        final_syl_sec = int(output.split(\" \")[1].strip())\n",
    "    except Exception as e:\n",
    "        print(output)\n",
    "    \n",
    "    return final_syl_sec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the program, make sure that ollama is installed (we used Homebrew). You can then use the 'ollama serve' to start Ollama up, use 'ollama pull mistral' to pull a specific LLM (mistral, in this case). \n",
    "\n",
    "You do have to specify the name in llm input variable to the ConversationChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "7lvktKT1g0HD",
    "outputId": "9fffd0e6-2dfc-4aec-a0d4-22ea67a328a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/jayabbhi/Documents/HCI_grad_project/lets-talk-tempo/sts/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "from rich.console import Console\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "stt = whisper.load_model(\"tiny\")\n",
    "console = Console()\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful and friendly AI assistant. You are polite and respectful. You will only give one response, in the same language as the input text.\n",
    "The conversation transcript is as follows:\n",
    "{history}\n",
    "And here is the user's follow-up: {input}\n",
    "Your response:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "chain = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    verbose=False,\n",
    "    memory=ConversationBufferMemory(ai_prefix=\"Assistant:\"),\n",
    "    llm=Ollama(model=\"mistral\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "eQjhQ5Qmg7Vv"
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "from scipy.signal import resample\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import time\n",
    "\n",
    "\n",
    "def record_audio(stop_event, data_queue):\n",
    "    \"\"\"\n",
    "    Captures audio data from the user's microphone and adds it to a queue for further processing.\n",
    "    Args:\n",
    "        stop_event (threading.Event): An event that, when set, signals the function to stop recording.\n",
    "        data_queue (queue.Queue): A queue to which the recorded audio data will be added.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    def callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            console.print(status)\n",
    "        data_queue.put(bytes(indata))\n",
    "\n",
    "    with sd.RawInputStream(\n",
    "        samplerate=44100, dtype=\"int32\", channels=1, callback=callback\n",
    "    ):\n",
    "\n",
    "        while not stop_event.is_set():\n",
    "            time.sleep(0.1)\n",
    "\n",
    "def transcribe(audio_np: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Transcribes the given audio data using the Whisper speech recognition model.\n",
    "    Args:\n",
    "        audio_np (numpy.ndarray): The audio data to be transcribed.\n",
    "    Returns:\n",
    "        str: The transcribed text.\n",
    "    \"\"\"\n",
    "    result = stt.transcribe(audio_np, fp16=False)  # Set fp16=True if using a GPU\n",
    "    text = result[\"text\"].strip()\n",
    "    return text\n",
    "\n",
    "def get_llm_response(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response to the given text using the Llama-2 language model.\n",
    "    Args:\n",
    "        text (str): The input text to be processed.\n",
    "    Returns:\n",
    "        str: The generated response.\n",
    "    \"\"\"\n",
    "    response = chain.predict(input=text)\n",
    "    if response.startswith(\"Assistant:\"):\n",
    "        response = response[len(\"Assistant:\") :].strip()\n",
    "    return response\n",
    "\n",
    "# def play_audio(audio_file):\n",
    "#     \"\"\"\n",
    "#     Plays the given audio data using the sounddevice library.\n",
    "#     Args:\n",
    "#         sample_rate (int): The sample rate of the audio data.\n",
    "#         audio_array (numpy.ndarray): The audio data to be played.\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "\n",
    "#     audio = AudioSegment.from_mp3(audio_file)\n",
    "\n",
    "#     # Convert to numpy array (this gives us access to the raw audio data)\n",
    "#     audio_data = np.array(audio.get_array_of_samples())\n",
    "\n",
    "    \n",
    "#     # Adjust the playback speed by resampling\n",
    "#     # For example, to double the speed:\n",
    "#     sd.play(audio_data, audio.frame_rate)\n",
    "#     sd.wait()\n",
    "\n",
    "def play_audio(audio_file, user_speech_rate):\n",
    "    audio_data, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Slow down the audio (e.g., 50% slower)\n",
    "    speed_factor = float(8.0 / user_speech_rate)\n",
    "    print(f'New speech rate: {speed_factor}')\n",
    "    audio_stretched = librosa.effects.time_stretch(audio_data, rate=speed_factor)\n",
    "\n",
    "    # Play the slowed-down audio\n",
    "    # sd.play(audio_stretched, sr)\n",
    "    sd.play(audio_stretched, sr)\n",
    "    sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "e9rpd7ffg-K9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Assistant started! Press Ctrl+C to exit.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAssistant started! Press Ctrl+C to exit.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Press Enter to start recording, then press Enter again to stop.</pre>\n"
      ],
      "text/plain": [
       "Press Enter to start recording, then press Enter again to stop."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132e1cea0797495a882d769a924e7c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">You:  What is the definition of the word erodosa claitis?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mYou:  What is the definition of the word erodosa claitis?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">File copied successfully from user_fr.wav to ../myprosody/myprosody/dataset/audioFiles/\n",
       "</pre>\n"
      ],
      "text/plain": [
       "File copied successfully from user_fr.wav to ../myprosody/myprosody/dataset/audioFiles/\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460289328794418f88bcd82677c08637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Speech Rate: 4 (syllables per second)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Assistant:  The term </span><span style=\"color: #008080; text-decoration-color: #008080\">\"erodosa claitis\"</span><span style=\"color: #008080; text-decoration-color: #008080\"> does not seem to be a standard medical or scientific term. It might be a </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">typo or an error in the provided phrase. If you meant a different term, kindly let me know so I can help you </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">better.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAssistant:  The term \u001b[0m\u001b[36m\"erodosa claitis\"\u001b[0m\u001b[36m does not seem to be a standard medical or scientific term. It might be a \u001b[0m\n",
       "\u001b[36mtypo or an error in the provided phrase. If you meant a different term, kindly let me know so I can help you \u001b[0m\n",
       "\u001b[36mbetter.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780aa9721a2f4e45970dd6d13a2e8174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New speech rate: 2.0\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New speech rate: 2.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">File user_fr.wav deleted successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "File user_fr.wav deleted successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">File gtts.mp3 deleted successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "File gtts.mp3 deleted successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">File ../myprosody/myprosody/dataset/audioFiles/user_fr.wav deleted successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "File ../myprosody/myprosody/dataset/audioFiles/user_fr.wav deleted successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Press Enter to start recording, then press Enter again to stop.</pre>\n"
      ],
      "text/plain": [
       "Press Enter to start recording, then press Enter again to stop."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd4cb0865a7410292ebea6bb05d002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">You: </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mYou: \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">File copied successfully from user_fr.wav to ../myprosody/myprosody/dataset/audioFiles/\n",
       "</pre>\n"
      ],
      "text/plain": [
       "File copied successfully from user_fr.wav to ../myprosody/myprosody/dataset/audioFiles/\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try again the sound of the audio was not clear\n",
      "\n",
      "User Speech Rate: 8 (syllables per second)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fff0e549de40de9c8409ac19fae67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Assistant:  Apologies for any confusion. Based on my research, the term </span><span style=\"color: #008080; text-decoration-color: #008080\">\"erodosa claitis\"</span><span style=\"color: #008080; text-decoration-color: #008080\"> does not appear to be a </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">recognized medical or scientific term. It might be a typo or an error in the provided phrase. If you meant a </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">different term, kindly let me know so I can help you better.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAssistant:  Apologies for any confusion. Based on my research, the term \u001b[0m\u001b[36m\"erodosa claitis\"\u001b[0m\u001b[36m does not appear to be a \u001b[0m\n",
       "\u001b[36mrecognized medical or scientific term. It might be a typo or an error in the provided phrase. If you meant a \u001b[0m\n",
       "\u001b[36mdifferent term, kindly let me know so I can help you better.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fffe3033acd4fd1a7104d5e4d48fb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New speech rate: 1.0\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New speech rate: 1.0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">Exiting...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[31mExiting\u001b[0m\u001b[31m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Session ended.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mSession ended.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "from gtts import gTTS\n",
    "\n",
    "sample_rate = 44100\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    console.print(\"[cyan]Assistant started! Press Ctrl+C to exit.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            console.input(\n",
    "                \"Press Enter to start recording, then press Enter again to stop.\"\n",
    "            )\n",
    "\n",
    "            data_queue = Queue()  # type: ignore[var-annotated]\n",
    "            stop_event = threading.Event()\n",
    "            recording_thread = threading.Thread(\n",
    "                target=record_audio,\n",
    "                args=(stop_event, data_queue),\n",
    "            )\n",
    "            recording_thread.start()\n",
    "\n",
    "            input()\n",
    "            stop_event.set()\n",
    "            recording_thread.join()\n",
    "\n",
    "            audio_data = b\"\".join(list(data_queue.queue))\n",
    "            audio_np = (np.frombuffer(audio_data, dtype=np.int32))\n",
    "\n",
    "            if audio_np.size > 0:\n",
    "                with console.status(\"Transcribing...\", spinner=\"earth\"):\n",
    "                    # The Audio file exists here, we can pass it along to myprosody\n",
    "                    wavfile.write('user_fr.wav', sample_rate, audio_np)\n",
    "                    transcr = (stt.transcribe('user_fr.wav'))['text']\n",
    "                # insert with method to extract the data speech rate method we need\n",
    "                console.print(f\"[yellow]You: {transcr}\")\n",
    "\n",
    "                with console.status(\"Extracting SR... \", spinner=\"earth\"):\n",
    "                    copy_file('../myprosody/myprosody/dataset/audioFiles/', 'user_fr.wav')\n",
    "                    user_sr = detect_sr('user_fr')\n",
    "                    print(f'User Speech Rate: {user_sr} (syllables per second)')\n",
    "\n",
    "                with console.status(\"Generating response...\", spinner=\"earth\"):\n",
    "                    response = get_llm_response(transcr)\n",
    "                    console.print(f\"[cyan]Assistant: {response}\")\n",
    "                    \n",
    "                # Generate, save, and play the audio\n",
    "                with console.status(\"Processing assistant audio..\", spinner=\"earth\"):\n",
    "                    tts = gTTS(text=response, lang='en')\n",
    "                    tts.save(\"gtts.mp3\")\n",
    "                    play_audio(\"gtts.mp3\", user_sr)\n",
    "\n",
    "                with console.status(\"Cleaninp up temp files..\", spinner=\"earth\"):\n",
    "                    delete_file(\"user_fr.wav\")\n",
    "                    delete_file(\"gtts.mp3\")\n",
    "                    delete_file(\"../myprosody/myprosody/dataset/audioFiles/user_fr.wav\")\n",
    "            else:\n",
    "                console.print(\n",
    "                    \"[red]No audio recorded. Please ensure your microphone is working.\"\n",
    "                )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        console.print(\"\\n[red]Exiting...\")\n",
    "\n",
    "    console.print(\"[blue]Session ended.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
