{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AbbhinavJayaraman/HCI-Grad-Course/blob/main/homegrown_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GbKnkZehINw"
   },
   "source": [
    "Since ChatGPT and existing LLMs are being annoying, we are just going to follow an existing setup that can be tweaked, making use of ollama since performance on one of our laptops running an modified Fedora Linux distrubtion was able tobe fast and responsive.\n",
    "\n",
    "Still need to figure out how to connect this with either the PRAAT scripts or myprosody:\n",
    "\n",
    "Links:\n",
    "Whisper + ollama + Bark framework: https://medium.com/@vndee.huynh/build-your-own-voice-assistant-and-run-it-locally-whisper-ollama-bark-c80e6f815cba\n",
    "\n",
    "PRAAT in python: https://github.com/YannickJadoul/Parselmouth\n",
    "myprosody: https://github.com/Shahabks/myprosody\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the following packages to install properly, you will need to make sure you on python version 3.12\n",
    "\n",
    "Install python version 3.12 (we used Homebrew), and then made a python venv with it (python3.12 -m venv sts), where sts is just a name of the venv.\n",
    "\n",
    "then you can activate the venv using source sts/bin/activate\n",
    "\n",
    "also make sure you have the portaudio library installed. For Mac, make use of the Homebrew package manager. \n",
    "\n",
    "For linux distrubitions, it's best to use the default package manager's version of portaudio, as well as the development headers (for us, that was portaudio-devel on Fedora Silverblue Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./sts/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./sts/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./sts/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./sts/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./sts/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in ./sts/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in ./sts/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./sts/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./sts/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./sts/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./sts/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./sts/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./sts/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./sts/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./sts/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./sts/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./sts/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./sts/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./sts/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in ./sts/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./sts/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./sts/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./sts/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./sts/lib/python3.12/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in ./sts/lib/python3.12/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in ./sts/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./sts/lib/python3.12/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./sts/lib/python3.12/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./sts/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./sts/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./sts/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./sts/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./sts/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./sts/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./sts/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./sts/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./sts/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./sts/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./sts/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./sts/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./sts/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai-whisper in ./sts/lib/python3.12/site-packages (20240930)\n",
      "Requirement already satisfied: numba in ./sts/lib/python3.12/site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in ./sts/lib/python3.12/site-packages (from openai-whisper) (2.0.2)\n",
      "Requirement already satisfied: torch in ./sts/lib/python3.12/site-packages (from openai-whisper) (2.5.1)\n",
      "Requirement already satisfied: tqdm in ./sts/lib/python3.12/site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in ./sts/lib/python3.12/site-packages (from openai-whisper) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in ./sts/lib/python3.12/site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in ./sts/lib/python3.12/site-packages (from openai-whisper) (3.1.0)\n",
      "Requirement already satisfied: filelock in ./sts/lib/python3.12/site-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./sts/lib/python3.12/site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./sts/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./sts/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: setuptools in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./sts/lib/python3.12/site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./sts/lib/python3.12/site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./sts/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./sts/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./sts/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./sts/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./sts/lib/python3.12/site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sounddevice in ./sts/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in ./sts/lib/python3.12/site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./sts/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rich in ./sts/lib/python3.12/site-packages (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./sts/lib/python3.12/site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./sts/lib/python3.12/site-packages (from rich) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./sts/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in ./sts/lib/python3.12/site-packages (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./sts/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./sts/lib/python3.12/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./sts/lib/python3.12/site-packages (from langchain) (3.11.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in ./sts/lib/python3.12/site-packages (from langchain) (0.3.22)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./sts/lib/python3.12/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./sts/lib/python3.12/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./sts/lib/python3.12/site-packages (from langchain) (2.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./sts/lib/python3.12/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in ./sts/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./sts/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./sts/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./sts/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./sts/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./sts/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./sts/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./sts/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./sts/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./sts/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./sts/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in ./sts/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./sts/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./sts/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./sts/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./sts/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_community in ./sts/lib/python3.12/site-packages (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./sts/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./sts/lib/python3.12/site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./sts/lib/python3.12/site-packages (from langchain_community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./sts/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in ./sts/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.10 in ./sts/lib/python3.12/site-packages (from langchain_community) (0.3.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in ./sts/lib/python3.12/site-packages (from langchain_community) (0.3.22)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./sts/lib/python3.12/site-packages (from langchain_community) (0.1.147)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./sts/lib/python3.12/site-packages (from langchain_community) (2.0.2)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./sts/lib/python3.12/site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in ./sts/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./sts/lib/python3.12/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./sts/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./sts/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./sts/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./sts/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.10->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./sts/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.10->langchain_community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./sts/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./sts/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./sts/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./sts/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./sts/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./sts/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./sts/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./sts/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./sts/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in ./sts/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./sts/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./sts/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./sts/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./sts/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./sts/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain_community) (2.27.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./sts/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./sts/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in ./sts/lib/python3.12/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in ./sts/lib/python3.12/site-packages (from scipy) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install torch\n",
    "%pip install numpy\n",
    "%pip install transformers\n",
    "%pip install openai-whisper\n",
    "%pip install sounddevice\n",
    "%pip install rich\n",
    "%pip install langchain\n",
    "%pip install langchain_community\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KdpTxq6DgvC2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /var/home/jayabbhi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "from transformers import AutoProcessor, BarkModel\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\",\n",
    ")\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "class TextToSpeechService:\n",
    "    def __init__(self, device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        \"\"\"\n",
    "        Initializes the TextToSpeechService class.\n",
    "        Args:\n",
    "            device (str, optional): The device to be used for the model, either \"cuda\" if a GPU is available or \"cpu\".\n",
    "            Defaults to \"cuda\" if available, otherwise \"cpu\".\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.processor = AutoProcessor.from_pretrained(\"suno/bark-small\")\n",
    "        self.model = BarkModel.from_pretrained(\"suno/bark-small\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def synthesize(self, text: str, voice_preset: str = \"v2/en_speaker_1\"):\n",
    "        \"\"\"\n",
    "        Synthesizes audio from the given text using the specified voice preset.\n",
    "        Args:\n",
    "            text (str): The input text to be synthesized.\n",
    "            voice_preset (str, optional): The voice preset to be used for the synthesis. Defaults to \"v2/en_speaker_1\".\n",
    "        Returns:\n",
    "            tuple: A tuple containing the sample rate and the generated audio array.\n",
    "        \"\"\"\n",
    "        inputs = self.processor(text, voice_preset=voice_preset, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            audio_array = self.model.generate(**inputs, pad_token_id=10000)\n",
    "\n",
    "        audio_array = audio_array.cpu().numpy().squeeze()\n",
    "        sample_rate = self.model.generation_config.sample_rate\n",
    "        return sample_rate, audio_array\n",
    "\n",
    "    def long_form_synthesize(self, text: str, voice_preset: str = \"v2/en_speaker_1\"):\n",
    "        \"\"\"\n",
    "        Synthesizes audio from the given long-form text using the specified voice preset.\n",
    "        Args:\n",
    "            text (str): The input text to be synthesized.\n",
    "            voice_preset (str, optional): The voice preset to be used for the synthesis. Defaults to \"v2/en_speaker_1\".\n",
    "        Returns:\n",
    "            tuple: A tuple containing the sample rate and the generated audio array.\n",
    "        \"\"\"\n",
    "        pieces = []\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        silence = np.zeros(int(0.25 * self.model.generation_config.sample_rate))\n",
    "\n",
    "        for sent in sentences:\n",
    "            sample_rate, audio_array = self.synthesize(sent, voice_preset)\n",
    "            pieces += [audio_array, silence.copy()]\n",
    "\n",
    "        return self.model.generation_config.sample_rate, np.concatenate(pieces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the program, make sure that ollama is installed (we used Homebrew). You can then use the 'ollama serve' to start Ollama up, use 'ollama pull mistral' to pull a specific LLM (mistral, in this case). \n",
    "\n",
    "You do have to specify the name in llm input variable to the ConversationChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "7lvktKT1g0HD",
    "outputId": "9fffd0e6-2dfc-4aec-a0d4-22ea67a328a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/home/jayabbhi/Documents/HCI_grad_project/lets-talk-tempo/sts/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/var/home/jayabbhi/Documents/HCI_grad_project/lets-talk-tempo/sts/lib/python3.12/site-packages/transformers/models/encodec/modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "/tmp/ipykernel_50070/3381271373.py:30: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory(ai_prefix=\"Assistant:\"),\n",
      "/tmp/ipykernel_50070/3381271373.py:31: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm=Ollama(model=\"mistral\"),\n",
      "/tmp/ipykernel_50070/3381271373.py:27: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  chain = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "from queue import Queue\n",
    "from rich.console import Console\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "console = Console()\n",
    "stt = whisper.load_model(\"base.en\")\n",
    "tts = TextToSpeechService()\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful and friendly AI assistant. You are polite, respectful, and aim to provide concise responses of less\n",
    "than 20 words.\n",
    "The conversation transcript is as follows:\n",
    "{history}\n",
    "And here is the user's follow-up: {input}\n",
    "Your response:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "chain = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    verbose=False,\n",
    "    memory=ConversationBufferMemory(ai_prefix=\"Assistant:\"),\n",
    "    llm=Ollama(model=\"mistral\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eQjhQ5Qmg7Vv"
   },
   "outputs": [],
   "source": [
    "def record_audio(stop_event, data_queue):\n",
    "    \"\"\"\n",
    "    Captures audio data from the user's microphone and adds it to a queue for further processing.\n",
    "    Args:\n",
    "        stop_event (threading.Event): An event that, when set, signals the function to stop recording.\n",
    "        data_queue (queue.Queue): A queue to which the recorded audio data will be added.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    def callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            console.print(status)\n",
    "        data_queue.put(bytes(indata))\n",
    "\n",
    "    with sd.RawInputStream(\n",
    "        samplerate=16000, dtype=\"int16\", channels=1, callback=callback\n",
    "    ):\n",
    "\n",
    "        while not stop_event.is_set():\n",
    "            time.sleep(0.1)\n",
    "\n",
    "def transcribe(audio_np: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Transcribes the given audio data using the Whisper speech recognition model.\n",
    "    Args:\n",
    "        audio_np (numpy.ndarray): The audio data to be transcribed.\n",
    "    Returns:\n",
    "        str: The transcribed text.\n",
    "    \"\"\"\n",
    "    result = stt.transcribe(audio_np, fp16=False)  # Set fp16=True if using a GPU\n",
    "    text = result[\"text\"].strip()\n",
    "    return text\n",
    "\n",
    "def get_llm_response(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response to the given text using the Llama-2 language model.\n",
    "    Args:\n",
    "        text (str): The input text to be processed.\n",
    "    Returns:\n",
    "        str: The generated response.\n",
    "    \"\"\"\n",
    "    response = chain.predict(input=text)\n",
    "    if response.startswith(\"Assistant:\"):\n",
    "        response = response[len(\"Assistant:\") :].strip()\n",
    "    return response\n",
    "\n",
    "def play_audio(sample_rate, audio_array):\n",
    "    \"\"\"\n",
    "    Plays the given audio data using the sounddevice library.\n",
    "    Args:\n",
    "        sample_rate (int): The sample rate of the audio data.\n",
    "        audio_array (numpy.ndarray): The audio data to be played.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    sd.play(audio_array, sample_rate)\n",
    "    sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e9rpd7ffg-K9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Assistant started! Press Ctrl+C to exit.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAssistant started! Press Ctrl+C to exit.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Press Enter to start recording, then press Enter again to stop.</pre>\n"
      ],
      "text/plain": [
       "Press Enter to start recording, then press Enter again to stop."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8c596c7fcd4d9fb5252107302df0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">You: Hello there, how was your day?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mYou: Hello there, how was your day?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ca2df2d35d40f6aa86bdd792dba398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edd7bb5bf3d4800be9cf74d1072e1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "en_speaker_1_semantic_prompt.npy:   0%|          | 0.00/2.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d2368ac2074bf8967d29071ed28bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "en_speaker_1_coarse_prompt.npy:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab96c959ac3a4f388de8faca402c21ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "en_speaker_1_fine_prompt.npy:   0%|          | 0.00/14.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Assistant:  I've been functioning well, thank you! How about yours?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAssistant:  I've been functioning well, thank you! How about yours?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Press Enter to start recording, then press Enter again to stop.</pre>\n"
      ],
      "text/plain": [
       "Press Enter to start recording, then press Enter again to stop."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29be932c9a942559f3dfd62178e0135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">You: </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mYou: \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45871908d864b23b4e77654af0984b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">Exiting...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[31mExiting\u001b[0m\u001b[31m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Session ended.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mSession ended.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    console.print(\"[cyan]Assistant started! Press Ctrl+C to exit.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            console.input(\n",
    "                \"Press Enter to start recording, then press Enter again to stop.\"\n",
    "            )\n",
    "\n",
    "            data_queue = Queue()  # type: ignore[var-annotated]\n",
    "            stop_event = threading.Event()\n",
    "            recording_thread = threading.Thread(\n",
    "                target=record_audio,\n",
    "                args=(stop_event, data_queue),\n",
    "            )\n",
    "            recording_thread.start()\n",
    "\n",
    "            input()\n",
    "            stop_event.set()\n",
    "            recording_thread.join()\n",
    "\n",
    "            audio_data = b\"\".join(list(data_queue.queue))\n",
    "            audio_np = (\n",
    "                np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "            )\n",
    "\n",
    "            if audio_np.size > 0:\n",
    "                with console.status(\"Transcribing...\", spinner=\"earth\"):\n",
    "                    # The Audio file exists here, we can pass it along to myprosody\n",
    "                    wavfile.write('output3.wav', 16000, audio_np)\n",
    "                    text = transcribe(audio_np)\n",
    "                console.print(f\"[yellow]You: {text}\")\n",
    "\n",
    "                with console.status(\"Generating response...\", spinner=\"earth\"):\n",
    "                    response = get_llm_response(text)\n",
    "                    sample_rate, audio_array = tts.long_form_synthesize(response)\n",
    "\n",
    "                console.print(f\"[cyan]Assistant: {response}\")\n",
    "                play_audio(sample_rate, audio_array)\n",
    "            else:\n",
    "                console.print(\n",
    "                    \"[red]No audio recorded. Please ensure your microphone is working.\"\n",
    "                )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        console.print(\"\\n[red]Exiting...\")\n",
    "\n",
    "    console.print(\"[blue]Session ended.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
